# Neural-Network-Optimizer-
## Overview
This project compares different optimization techniques for training a Convolutional Neural Network (CNN) on the CIFAR-10 dataset. The optimizers used are:
- Mini-batch Stochastic Gradient Descent (SGD)
- Adam
- RMSprop
- AdaGrad

## Requirements
To run this code, you will need the following Python packages:

- TensorFlow
- NumPy
- Matplotlib
- Keras
- OpenCV (for image processing)
- tracemalloc (for memory profiling)

## 
